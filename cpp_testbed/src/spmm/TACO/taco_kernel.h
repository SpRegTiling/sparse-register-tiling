// Generated by the Tensor Algebra Compiler (tensor-compiler.org)
// bin/taco "C(i,k)=A(i,j)*B(j,k)" -f=C:dd -f=A:ds -f=B:dd -t=A:float -t=B:float -t=C:float -s="split(i,i0,i1,16)" -s="pos(j,jpos,A)" -s="split(jpos,jpos0,jpos1,16)" -s="reorder(i0,i1,jpos0,k,jpos1)" -s="parallelize(i0,CPUThread,NoRaces)" -s="parallelize(k,CPUVector,IgnoreRaces)" -write-source=taco_kernel.h
#ifndef TACO_C_HEADERS
#define TACO_C_HEADERS
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <stdbool.h>
#include <math.h>
#include <complex.h>
#include <string.h>
#if _OPENMP
#include <omp.h>
#endif
#define TACO_MIN(_a,_b) ((_a) < (_b) ? (_a) : (_b))
#define TACO_MAX(_a,_b) ((_a) > (_b) ? (_a) : (_b))
#define TACO_DEREF(_a) (((___context___*)(*__ctx__))->_a)
#ifndef TACO_TENSOR_T_DEFINED
#define TACO_TENSOR_T_DEFINED
typedef enum { taco_mode_dense, taco_mode_sparse } taco_mode_t;
typedef struct {
  int32_t      order;         // tensor order (number of modes)
  int32_t*     dimensions;    // tensor dimensions
  int32_t      csize;         // component size
  int32_t*     mode_ordering; // mode storage ordering
  taco_mode_t* mode_types;    // mode storage types
  uint8_t***   indices;       // tensor index data (per mode)
  uint8_t*     vals;          // tensor values
  uint8_t*     fill_value;    // tensor fill value
  int32_t      vals_size;     // values array size
} taco_tensor_t;
#endif
#if !_OPENMP
int omp_get_thread_num() { return 0; }
int omp_get_max_threads() { return 1; }
#endif
int cmp(const void *a, const void *b) {
  return *((const int*)a) - *((const int*)b);
}
int taco_gallop(int *array, int arrayStart, int arrayEnd, int target) {
  if (array[arrayStart] >= target || arrayStart >= arrayEnd) {
    return arrayStart;
  }
  int step = 1;
  int curr = arrayStart;
  while (curr + step < arrayEnd && array[curr + step] < target) {
    curr += step;
    step = step * 2;
  }

  step = step / 2;
  while (step > 0) {
    if (curr + step < arrayEnd && array[curr + step] < target) {
      curr += step;
    }
    step = step / 2;
  }
  return curr+1;
}
int taco_binarySearchAfter(int *array, int arrayStart, int arrayEnd, int target) {
  if (array[arrayStart] >= target) {
    return arrayStart;
  }
  int lowerBound = arrayStart; // always < target
  int upperBound = arrayEnd; // always >= target
  while (upperBound - lowerBound > 1) {
    int mid = (upperBound + lowerBound) / 2;
    int midValue = array[mid];
    if (midValue < target) {
      lowerBound = mid;
    }
    else if (midValue > target) {
      upperBound = mid;
    }
    else {
      return mid;
    }
  }
  return upperBound;
}
int taco_binarySearchBefore(int *array, int arrayStart, int arrayEnd, int target) {
  if (array[arrayEnd] <= target) {
    return arrayEnd;
  }
  int lowerBound = arrayStart; // always <= target
  int upperBound = arrayEnd; // always > target
  while (upperBound - lowerBound > 1) {
    int mid = (upperBound + lowerBound) / 2;
    int midValue = array[mid];
    if (midValue < target) {
      lowerBound = mid;
    }
    else if (midValue > target) {
      upperBound = mid;
    }
    else {
      return mid;
    }
  }
  return lowerBound;
}
taco_tensor_t* init_taco_tensor_t(int32_t order, int32_t csize,
                                  int32_t* dimensions, int32_t* mode_ordering,
                                  taco_mode_t* mode_types) {
  taco_tensor_t* t = (taco_tensor_t *) malloc(sizeof(taco_tensor_t));
  t->order         = order;
  t->dimensions    = (int32_t *) malloc(order * sizeof(int32_t));
  t->mode_ordering = (int32_t *) malloc(order * sizeof(int32_t));
  t->mode_types    = (taco_mode_t *) malloc(order * sizeof(taco_mode_t));
  t->indices       = (uint8_t ***) malloc(order * sizeof(uint8_t***));
  t->csize         = csize;
  for (int32_t i = 0; i < order; i++) {
    t->dimensions[i]    = dimensions[i];
    t->mode_ordering[i] = mode_ordering[i];
    t->mode_types[i]    = mode_types[i];
    switch (t->mode_types[i]) {
      case taco_mode_dense:
        t->indices[i] = (uint8_t **) malloc(1 * sizeof(uint8_t **));
        break;
      case taco_mode_sparse:
        t->indices[i] = (uint8_t **) malloc(2 * sizeof(uint8_t **));
        break;
    }
  }
  return t;
}
void deinit_taco_tensor_t(taco_tensor_t* t) {
  for (int i = 0; i < t->order; i++) {
    free(t->indices[i]);
  }
  free(t->indices);
  free(t->dimensions);
  free(t->mode_ordering);
  free(t->mode_types);
  free(t);
}
#endif

int compute(taco_tensor_t *C, taco_tensor_t *A, taco_tensor_t *B) {
  int C1_dimension = (int)(C->dimensions[0]);
  int C2_dimension = (int)(C->dimensions[1]);
  float* restrict C_vals = (float*)(C->vals);
  int A1_dimension = (int)(A->dimensions[0]);
  int* restrict A2_pos = (int*)(A->indices[1][0]);
  int* restrict A2_crd = (int*)(A->indices[1][1]);
  float* restrict A_vals = (float*)(A->vals);
  int B1_dimension = (int)(B->dimensions[0]);
  int B2_dimension = (int)(B->dimensions[1]);
  float* restrict B_vals = (float*)(B->vals);

  #pragma omp parallel for schedule(static)
  for (int32_t pC = 0; pC < (C1_dimension * C2_dimension); pC++) {
    C_vals[pC] = 0.0;
  }

  #pragma omp parallel for schedule(runtime)
  for (int32_t i0 = 0; i0 < ((A1_dimension + 15) / 16); i0++) {
    for (int32_t i1 = 0; i1 < 16; i1++) {
      int32_t i = i0 * 16 + i1;
      if (i >= A1_dimension)
        continue;

      for (int32_t jpos0 = A2_pos[i] / 16; jpos0 < ((A2_pos[(i + 1)] + 15) / 16); jpos0++) {
        if (jpos0 * 16 < A2_pos[i] || (jpos0 * 16 + 16) + ((jpos0 * 16 + 16) - jpos0 * 16) >= A2_pos[(i + 1)]) {
          for (int32_t k = 0; k < B2_dimension; k++) {
            int32_t kC = i * C2_dimension + k;
            float tjpos1C_val = 0.0;
            for (int32_t jpos1 = 0; jpos1 < 16; jpos1++) {
              int32_t jposA = jpos0 * 16 + jpos1;
              if (jposA < A2_pos[i] || jposA >= A2_pos[(i + 1)])
                continue;

              int32_t j = A2_crd[jposA];
              int32_t kB = j * B2_dimension + k;
              tjpos1C_val += A_vals[jposA] * B_vals[kB];
            }
            C_vals[kC] = C_vals[kC] + tjpos1C_val;
          }
        }
        else {
          #pragma clang loop interleave(enable) vectorize(enable)
          for (int32_t k = 0; k < B2_dimension; k++) {
            int32_t kC = i * C2_dimension + k;
            float tjpos1C_val0 = 0.0;
            for (int32_t jpos1 = 0; jpos1 < 16; jpos1++) {
              int32_t jposA = jpos0 * 16 + jpos1;
              int32_t j = A2_crd[jposA];
              int32_t kB = j * B2_dimension + k;
              tjpos1C_val0 += A_vals[jposA] * B_vals[kB];
            }
            C_vals[kC] = C_vals[kC] + tjpos1C_val0;
          }
        }
      }
    }
  }
  return 0;
}

int assemble(taco_tensor_t *C, taco_tensor_t *A, taco_tensor_t *B) {
  int C1_dimension = (int)(C->dimensions[0]);
  int C2_dimension = (int)(C->dimensions[1]);
  float* restrict C_vals = (float*)(C->vals);

  C_vals = (float*)malloc(sizeof(float) * (C1_dimension * C2_dimension));

  C->vals = (uint8_t*)C_vals;
  return 0;
}

int evaluate(taco_tensor_t *C, taco_tensor_t *A, taco_tensor_t *B) {
  int C1_dimension = (int)(C->dimensions[0]);
  int C2_dimension = (int)(C->dimensions[1]);
  float* restrict C_vals = (float*)(C->vals);
  int A1_dimension = (int)(A->dimensions[0]);
  int* restrict A2_pos = (int*)(A->indices[1][0]);
  int* restrict A2_crd = (int*)(A->indices[1][1]);
  float* restrict A_vals = (float*)(A->vals);
  int B1_dimension = (int)(B->dimensions[0]);
  int B2_dimension = (int)(B->dimensions[1]);
  float* restrict B_vals = (float*)(B->vals);

  int32_t C_capacity = C1_dimension * C2_dimension;
  C_vals = (float*)malloc(sizeof(float) * C_capacity);

  #pragma omp parallel for schedule(static)
  for (int32_t pC = 0; pC < C_capacity; pC++) {
    C_vals[pC] = 0.0;
  }

  #pragma omp parallel for schedule(runtime)
  for (int32_t i0 = 0; i0 < ((A1_dimension + 15) / 16); i0++) {
    for (int32_t i1 = 0; i1 < 16; i1++) {
      int32_t i = i0 * 16 + i1;
      if (i >= A1_dimension)
        continue;

      for (int32_t jpos0 = A2_pos[i] / 16; jpos0 < ((A2_pos[(i + 1)] + 15) / 16); jpos0++) {
        if (jpos0 * 16 < A2_pos[i] || (jpos0 * 16 + 16) + ((jpos0 * 16 + 16) - jpos0 * 16) >= A2_pos[(i + 1)]) {
          for (int32_t k = 0; k < B2_dimension; k++) {
            int32_t kC = i * C2_dimension + k;
            float tjpos1C_val = 0.0;
            for (int32_t jpos1 = 0; jpos1 < 16; jpos1++) {
              int32_t jposA = jpos0 * 16 + jpos1;
              if (jposA < A2_pos[i] || jposA >= A2_pos[(i + 1)])
                continue;

              int32_t j = A2_crd[jposA];
              int32_t kB = j * B2_dimension + k;
              tjpos1C_val += A_vals[jposA] * B_vals[kB];
            }
            C_vals[kC] = C_vals[kC] + tjpos1C_val;
          }
        }
        else {
          #pragma clang loop interleave(enable) vectorize(enable)
          for (int32_t k = 0; k < B2_dimension; k++) {
            int32_t kC = i * C2_dimension + k;
            float tjpos1C_val0 = 0.0;
            for (int32_t jpos1 = 0; jpos1 < 16; jpos1++) {
              int32_t jposA = jpos0 * 16 + jpos1;
              int32_t j = A2_crd[jposA];
              int32_t kB = j * B2_dimension + k;
              tjpos1C_val0 += A_vals[jposA] * B_vals[kB];
            }
            C_vals[kC] = C_vals[kC] + tjpos1C_val0;
          }
        }
      }
    }
  }

  C->vals = (uint8_t*)C_vals;
  return 0;
}

/*
 * The `pack` functions convert coordinate and value arrays in COO format,
 * with nonzeros sorted lexicographically by their coordinates, to the
 * specified input format.
 *
 * The `unpack` function converts the specified output format to coordinate
 * and value arrays in COO format.
 *
 * For both, the `_COO_pos` arrays contain two elements, where the first is 0
 * and the second is the number of nonzeros in the tensor.
 */

int pack_A(taco_tensor_t *A, int* A_COO1_pos, int* A_COO1_crd, int* A_COO2_crd, float* A_COO_vals) {
  int A1_dimension = (int)(A->dimensions[0]);
  int* restrict A2_pos = (int*)(A->indices[1][0]);
  int* restrict A2_crd = (int*)(A->indices[1][1]);
  float* restrict A_vals = (float*)(A->vals);

  A2_pos = (int32_t*)malloc(sizeof(int32_t) * (A1_dimension + 1));
  A2_pos[0] = 0;
  for (int32_t pA2 = 1; pA2 < (A1_dimension + 1); pA2++) {
    A2_pos[pA2] = 0;
  }
  int32_t A2_crd_size = 1048576;
  A2_crd = (int32_t*)malloc(sizeof(int32_t) * A2_crd_size);
  int32_t jA = 0;
  int32_t A_capacity = 1048576;
  A_vals = (float*)malloc(sizeof(float) * A_capacity);

  int32_t iA_COO = A_COO1_pos[0];
  int32_t pA_COO1_end = A_COO1_pos[1];

  while (iA_COO < pA_COO1_end) {
    int32_t i = A_COO1_crd[iA_COO];
    int32_t A_COO1_segend = iA_COO + 1;
    while (A_COO1_segend < pA_COO1_end && A_COO1_crd[A_COO1_segend] == i) {
      A_COO1_segend++;
    }
    int32_t pA2_begin = jA;

    int32_t jA_COO = iA_COO;

    while (jA_COO < A_COO1_segend) {
      int32_t j = A_COO2_crd[jA_COO];
      float A_COO_val = A_COO_vals[jA_COO];
      jA_COO++;
      while (jA_COO < A_COO1_segend && A_COO2_crd[jA_COO] == j) {
        A_COO_val += A_COO_vals[jA_COO];
        jA_COO++;
      }
      if (A_capacity <= jA) {
        A_vals = (float*)realloc(A_vals, sizeof(float) * (A_capacity * 2));
        A_capacity *= 2;
      }
      A_vals[jA] = A_COO_val;
      if (A2_crd_size <= jA) {
        A2_crd = (int32_t*)realloc(A2_crd, sizeof(int32_t) * (A2_crd_size * 2));
        A2_crd_size *= 2;
      }
      A2_crd[jA] = j;
      jA++;
    }

    A2_pos[i + 1] = jA - pA2_begin;
    iA_COO = A_COO1_segend;
  }

  int32_t csA2 = 0;
  for (int32_t pA20 = 1; pA20 < (A1_dimension + 1); pA20++) {
    csA2 += A2_pos[pA20];
    A2_pos[pA20] = csA2;
  }

  A->indices[1][0] = (uint8_t*)(A2_pos);
  A->indices[1][1] = (uint8_t*)(A2_crd);
  A->vals = (uint8_t*)A_vals;
  return 0;
}

int pack_B(taco_tensor_t *B, int* B_COO1_pos, int* B_COO1_crd, int* B_COO2_crd, float* B_COO_vals) {
  int B1_dimension = (int)(B->dimensions[0]);
  int B2_dimension = (int)(B->dimensions[1]);
  float* restrict B_vals = (float*)(B->vals);

  int32_t B_capacity = B1_dimension * B2_dimension;
  B_vals = (float*)malloc(sizeof(float) * B_capacity);

  #pragma omp parallel for schedule(static)
  for (int32_t pB = 0; pB < B_capacity; pB++) {
    B_vals[pB] = 0.0;
  }

  int32_t jB_COO = B_COO1_pos[0];
  int32_t pB_COO1_end = B_COO1_pos[1];

  while (jB_COO < pB_COO1_end) {
    int32_t j = B_COO1_crd[jB_COO];
    int32_t B_COO1_segend = jB_COO + 1;
    while (B_COO1_segend < pB_COO1_end && B_COO1_crd[B_COO1_segend] == j) {
      B_COO1_segend++;
    }
    int32_t kB_COO = jB_COO;

    while (kB_COO < B_COO1_segend) {
      int32_t k = B_COO2_crd[kB_COO];
      float B_COO_val = B_COO_vals[kB_COO];
      kB_COO++;
      while (kB_COO < B_COO1_segend && B_COO2_crd[kB_COO] == k) {
        B_COO_val += B_COO_vals[kB_COO];
        kB_COO++;
      }
      int32_t kB = j * B2_dimension + k;
      B_vals[kB] = B_COO_val;
    }
    jB_COO = B_COO1_segend;
  }

  B->vals = (uint8_t*)B_vals;
  return 0;
}

int unpack(int** C_COO1_pos_ptr, int** C_COO1_crd_ptr, int** C_COO2_crd_ptr, float** C_COO_vals_ptr, taco_tensor_t *C) {
  int* C_COO1_pos;
  int* C_COO1_crd;
  int* C_COO2_crd;
  float* C_COO_vals;
  int C1_dimension = (int)(C->dimensions[0]);
  int C2_dimension = (int)(C->dimensions[1]);
  float* restrict C_vals = (float*)(C->vals);

  C_COO1_pos = (int32_t*)malloc(sizeof(int32_t) * 2);
  C_COO1_pos[0] = 0;
  int32_t C_COO1_crd_size = 1048576;
  C_COO1_crd = (int32_t*)malloc(sizeof(int32_t) * C_COO1_crd_size);
  int32_t C_COO2_crd_size = 1048576;
  C_COO2_crd = (int32_t*)malloc(sizeof(int32_t) * C_COO2_crd_size);
  int32_t kC_COO = 0;
  int32_t C_COO_capacity = 1048576;
  C_COO_vals = (float*)malloc(sizeof(float) * C_COO_capacity);


  for (int32_t i = 0; i < C1_dimension; i++) {
    for (int32_t k = 0; k < C2_dimension; k++) {
      if (C_COO_capacity <= kC_COO) {
        C_COO_vals = (float*)realloc(C_COO_vals, sizeof(float) * (C_COO_capacity * 2));
        C_COO_capacity *= 2;
      }
      int32_t kC = i * C2_dimension + k;
      C_COO_vals[kC_COO] = C_vals[kC];
      if (C_COO2_crd_size <= kC_COO) {
        int32_t C_COO2_crd_new_size = TACO_MAX(C_COO2_crd_size * 2,(kC_COO + 1));
        C_COO2_crd = (int32_t*)realloc(C_COO2_crd, sizeof(int32_t) * C_COO2_crd_new_size);
        C_COO2_crd_size = C_COO2_crd_new_size;
      }
      C_COO2_crd[kC_COO] = k;
      if (C_COO1_crd_size <= kC_COO) {
        C_COO1_crd = (int32_t*)realloc(C_COO1_crd, sizeof(int32_t) * (C_COO1_crd_size * 2));
        C_COO1_crd_size *= 2;
      }
      C_COO1_crd[kC_COO] = i;
      kC_COO++;
    }
  }

  C_COO1_pos[1] = kC_COO;

  *C_COO1_pos_ptr = C_COO1_pos;
  *C_COO1_crd_ptr = C_COO1_crd;
  *C_COO2_crd_ptr = C_COO2_crd;
  *C_COO_vals_ptr = C_COO_vals;
  return 0;
}
